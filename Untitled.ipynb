{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b866a628-0653-4733-916f-fab094624da7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ktransformer.py     dataset.py\t      multi_head_attn.py  train.ipynb\n",
      "Log\t\t    fastMRI\t      params.csv\t  train.py\n",
      "README.md\t    fftc.py\t      perform_tl.py\t  utils.py\n",
      "Untitled.ipynb\t    generate_mask.py  requirements.txt\t  visualisation.ipynb\n",
      "__pycache__\t    layers.py\t      sampling.py\n",
      "data_preprocess.py  main.py\t      test.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7d0a119-1610-48bb-99d4-07c14c96020d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"perform_tl.py\", line 136, in <module>\n",
      "    perform_tl(model, config.modelPath,device)\n",
      "  File \"perform_tl.py\", line 41, in perform_tl\n",
      "    checkpoint = torch.load(model_Path)\n",
      "  File \"/home/mainuser/.local/lib/python3.8/site-packages/torch/serialization.py\", line 809, in load\n",
      "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/home/mainuser/.local/lib/python3.8/site-packages/torch/serialization.py\", line 1172, in _load\n",
      "    result = unpickler.load()\n",
      "  File \"/home/mainuser/.local/lib/python3.8/site-packages/torch/serialization.py\", line 1142, in persistent_load\n",
      "    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n",
      "  File \"/home/mainuser/.local/lib/python3.8/site-packages/torch/serialization.py\", line 1116, in load_tensor\n",
      "    wrap_storage=restore_location(storage, location),\n",
      "  File \"/home/mainuser/.local/lib/python3.8/site-packages/torch/serialization.py\", line 217, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"/home/mainuser/.local/lib/python3.8/site-packages/torch/serialization.py\", line 187, in _cuda_deserialize\n",
      "    return obj.cuda(device)\n",
      "  File \"/home/mainuser/.local/lib/python3.8/site-packages/torch/_utils.py\", line 81, in _cuda\n",
      "    untyped_storage = torch.UntypedStorage(\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 perform_tl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6845407f-21a2-405d-b6ea-bd366d216ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  7 01:34:58 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.85.02    Driver Version: 510.85.02    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    66W / 300W |  80862MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a324d-0a76-443a-a418-97ae82713220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
